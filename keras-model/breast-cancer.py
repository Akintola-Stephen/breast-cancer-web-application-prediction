import numpy as npfrom sklearn.model_selection import train_test_splitimport sklearnimport kerasfrom keras import backend as Kfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpointfrom keras.preprocessing.image import ImageDataGeneratorfrom keras.utils.np_utils import to_categoricalfrom keras.models import Sequential, model_from_jsonfrom keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadeltafrom keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2DX = np.load('./archive/X.npy')Y = np.load('./archive/Y.npy')def describe(a, b):    print('Total number of images: {}'.format(len(a)))    print('Number of IDC(-) Images: {}'.format(np.sum(b==0)))    print('Number of IDC(+) Images: {}'.format(np.sum(b==1)))    print('Percentage of positive images: {:.2f}%'.format(100*np.mean(b)))    print('Image shape (Width, Height, Channels): {}'.format(a[0].shape))describe(X,Y)X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)# Reduce Sample Size for DeBuggingX_train = X_train[0:30000]Y_train = Y_train[0:30000]X_test = X_test[0:30000]Y_test = Y_test[0:30000]# Normalize the dataX_train = X_train / 256.0X_test = X_test / 256.0print("Training Data Shape:", X_train.shape, X_train.shape)print("Testing Data Shape:", X_test.shape, X_test.shape)Y_train = to_categorical(Y_train, 2)Y_test = to_categorical(Y_test, 2)classes = np.unique(Y_train)n_classes = len(classes)print('Total number of outputs : ', n_classes)print('Output classes : ', classes)class MetricsCheckpoint(Callback):    """Callback that saves metrics after each epoch"""    def __init__(self, savepath):        super(MetricsCheckpoint, self).__init__()        self.savepath = savepath        self.history = {}    def on_epoch_end(self, epoch, logs=None):        for k, v in logs.items():            self.history.setdefault(k, []).append(v)        np.save(self.savepath, self.history)def run_keras_CNN(a, b, c, d):    """    https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py    """    batch_size = 128    num_classes = 2    epochs = 5    img_rows, img_cols = X_train.shape[1], X_train.shape[2]    input_shape = (img_rows, img_cols, 3)    x_train = a    y_train = b    x_test = c    y_test = d    model = Sequential()    model.add(Conv2D(32, kernel_size=(3, 3),                     activation='relu',                     input_shape=input_shape))    model.add(Conv2D(64, (3, 3), activation='relu'))    model.add(MaxPooling2D(pool_size=(2, 2)))    model.add(Dropout(0.25))    model.add(Flatten())    model.add(Dense(128, activation='relu'))    model.add(Dropout(0.5))    model.add(Dense(num_classes, activation='softmax'))    model.compile(loss=keras.losses.categorical_crossentropy,                  optimizer=keras.optimizers.Adadelta(),                  metrics=['accuracy'])    model.fit(x_train, y_train,              batch_size=batch_size,              verbose=1,              epochs=epochs,              validation_data=(x_test, y_test), callbacks=[MetricsCheckpoint('logs')])    model.save('my_model.h5')    score = model.evaluate(x_test, y_test, verbose=0)    print('\nKeras CNN #1A - accuracy:', score[1], '\n')run_keras_CNN(X_train, Y_train, X_test, Y_test)